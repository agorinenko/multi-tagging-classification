{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gorinenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gorinenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import lightning as L\n",
    "    \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "В второй части w2v_base_line.ipynb мы составили базовый pipeline обучение модели CatBoostClassifier на базе признаков, извлеченных с использованием Word2Vec. В этом документе попробуем использовать рекурентные сети для предсказания меток-тегов и сравним скорость обучения модели и ее предсказательную способность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples count 5000\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "file_path = 'data/clear_stackoverflow_posts.csv'\n",
    "vocab_file_path = 'data/vocab_stackoverflow_posts.pkl'\n",
    "# file_path = '/content/drive/MyDrive/clear_stackoverflow_posts.csv'\n",
    "\n",
    "nrows = 5_000\n",
    "# 300_000\n",
    "df = pd.read_csv(file_path, nrows=nrows, index_col='idx', \n",
    "                 converters={'Tokenize_title': literal_eval, 'Tokenize_body': literal_eval, 'Tags': literal_eval})\n",
    "# Всего - 912090\n",
    "\n",
    "print(f'samples count {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Tokenize_title</th>\n",
       "      <th>Tokenize_body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как из скрипта на Питоне послать письмо с влож...</td>\n",
       "      <td>&lt;p&gt;Нужен простейший пример посылки письма с вл...</td>\n",
       "      <td>[python, smtp]</td>\n",
       "      <td>[скрипта, питоне, послать, письмо, вложением]</td>\n",
       "      <td>[нужен, простейший, пример, посылки, письма, в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как из скрипта на Питоне послать письмо с влож...</td>\n",
       "      <td>&lt;p&gt;Нужен простейший пример посылки письма с вл...</td>\n",
       "      <td>[python, smtp]</td>\n",
       "      <td>[скрипта, питоне, послать, письмо, вложением]</td>\n",
       "      <td>[нужен, простейший, пример, посылки, письма, в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как сохранить и восстановить базу данных Postg...</td>\n",
       "      <td>&lt;p&gt;Например, имеется пользователь &lt;em&gt;postgres...</td>\n",
       "      <td>[postgresql]</td>\n",
       "      <td>[сохранить, восстановить, базу, данных, postgr...</td>\n",
       "      <td>[например, имеется, пользователь, postgres, ба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как сохранить и восстановить базу данных Postg...</td>\n",
       "      <td>&lt;p&gt;Например, имеется пользователь &lt;em&gt;postgres...</td>\n",
       "      <td>[postgresql]</td>\n",
       "      <td>[сохранить, восстановить, базу, данных, postgr...</td>\n",
       "      <td>[например, имеется, пользователь, postgres, ба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Как найти файл по имени в папках командой из т...</td>\n",
       "      <td>&lt;p&gt;Какая команда Linux наиболее подходит подоб...</td>\n",
       "      <td>[linux, файлы]</td>\n",
       "      <td>[найти, файл, имени, папках, командой, терминала]</td>\n",
       "      <td>[команда, linux, наиболее, подходит, подобного...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "idx                                                      \n",
       "0    Как из скрипта на Питоне послать письмо с влож...   \n",
       "1    Как из скрипта на Питоне послать письмо с влож...   \n",
       "2    Как сохранить и восстановить базу данных Postg...   \n",
       "3    Как сохранить и восстановить базу данных Postg...   \n",
       "4    Как найти файл по имени в папках командой из т...   \n",
       "\n",
       "                                                  Body            Tags  \\\n",
       "idx                                                                      \n",
       "0    <p>Нужен простейший пример посылки письма с вл...  [python, smtp]   \n",
       "1    <p>Нужен простейший пример посылки письма с вл...  [python, smtp]   \n",
       "2    <p>Например, имеется пользователь <em>postgres...    [postgresql]   \n",
       "3    <p>Например, имеется пользователь <em>postgres...    [postgresql]   \n",
       "4    <p>Какая команда Linux наиболее подходит подоб...  [linux, файлы]   \n",
       "\n",
       "                                        Tokenize_title  \\\n",
       "idx                                                      \n",
       "0        [скрипта, питоне, послать, письмо, вложением]   \n",
       "1        [скрипта, питоне, послать, письмо, вложением]   \n",
       "2    [сохранить, восстановить, базу, данных, postgr...   \n",
       "3    [сохранить, восстановить, базу, данных, postgr...   \n",
       "4    [найти, файл, имени, папках, командой, терминала]   \n",
       "\n",
       "                                         Tokenize_body  \n",
       "idx                                                     \n",
       "0    [нужен, простейший, пример, посылки, письма, в...  \n",
       "1    [нужен, простейший, пример, посылки, письма, в...  \n",
       "2    [например, имеется, пользователь, postgres, ба...  \n",
       "3    [например, имеется, пользователь, postgres, ба...  \n",
       "4    [команда, linux, наиболее, подходит, подобного...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def parse_tags(value):\n",
    "#     tags = value.replace('<', '').split('>')\n",
    "#     return [tag for tag in tags if tag]\n",
    "\n",
    "    \n",
    "# df[\"Tags\"] = df[\"Tags\"].apply(lambda x: parse_tags(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "\n",
    "class TextPreProcessor:\n",
    "    def __init__(self, tokenizer, stemmer=None, morph=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.morph = morph\n",
    "\n",
    "\n",
    "    def tokenize(self, text: str):      \n",
    "        text = text.lower()\n",
    "      \n",
    "        doc = BeautifulSoup(text, 'lxml')\n",
    "        text = doc.text\n",
    "        \n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        words = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "        \n",
    "        if self.morph:\n",
    "            words = [self.morph.parse(word)[0].normal_form for word in words]\n",
    "\n",
    "        if self.stemmer:\n",
    "            words = [self.stemmer.stem(word) for word in words]\n",
    "\n",
    "        return words\n",
    "    \n",
    "class NltkTokenizer:    \n",
    "    def tokenize(self, text: str):      \n",
    "        return list(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим словарь, который сопоставляет словам некие индексы. Мы используем специальный токен **unk**, который будет возвращен, если слово отсутствует в словаре. Внутри себя функция подсчитывает частоту появления каждого токена, потом слова сортируются по убыванию частоты и из уже отсортированного словаря строиться vocab. Таким образом самые часто встречаемые слова будут в начале(специальный токен **unk** имеет индекс 0). В словаре также имеется токен **pad**, который дополняет предложение до определенной длины, если оно меньше, например, если мы условились, что длина последовательности равна 10, то предложение 'here is the an example' будет закодировано так 'here is the an example pad pad pad pad pad'. Только на месте чисел должны стоять их индексы в словаре.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    if not isinstance(text, str):\n",
    "          return text\n",
    "      \n",
    "    tokenizer = TextPreProcessor(tokenizer=NltkTokenizer())    \n",
    "    words = tokenizer.tokenize(text)\n",
    "    return words\n",
    "    \n",
    "def yield_tokens(data_iter):\n",
    "    for tokens in data_iter:\n",
    "        yield preprocessor(tokens)\n",
    "        \n",
    "# df['Body'] = df['Body'].apply(lambda x: preprocessor(x))\n",
    "        \n",
    "# vocab = build_vocab_from_iterator(yield_tokens(df['Body']), specials=['<unk>', '<pad>'])\n",
    "with open(vocab_file_path ,'rb') as file:\n",
    "    vocab = pickle.load(file)\n",
    "    vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря 3045966\n",
      "Индексы слов [473, 12374, 0, 0]\n",
      "Слово с индексом 100 - \"and\"\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер словаря {len(vocab)}')\n",
    "print(f'Индексы слов {vocab([\"javascript\", \"принтер\", \"abra-cadabra\", \"<unk>\"])}')\n",
    "print(f'Слово с индексом 100 - \"{vocab.lookup_token(100)}\"')\n",
    "\n",
    "PAD_INDEX=vocab['<pad>']\n",
    "UNK_INDEX=vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label = MultiLabelBinarizer()\n",
    "Y = multi_label.fit_transform(list(df[\"Tags\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, создадим WordDataset и DataLoader с использованием функции collate_batch, которая будет формировать пакеты наших данных. Обратите внимание, что архитектура RNN требует, чтобы все предложения в пакете данных для обучения на каком-то шаге имели одинаковую длину. Поэтому в процессе формирования пакетов преобразуем токены текста в индексы подготовленного словаря, а затем дополним последовательности индексом специального символа **pad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset:\n",
    "    def __init__(self, data,  encode_labels=None):\n",
    "        self.data = data\n",
    "        self.encode_labels = encode_labels \n",
    "        assert len(self.data) == len(self.encode_labels)\n",
    "        \n",
    "    def _get_row(self, idx):\n",
    "        return self.data.iloc[idx]['Tokenize_body'] + self.data.iloc[idx]['Tokenize_title']\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.encode_labels is None:\n",
    "            return None, self._get_row(idx)\n",
    "        \n",
    "        return self.encode_labels[idx], self._get_row(idx)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "random_state=42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text_pipeline = lambda x: vocab(x)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = None, [], []\n",
    "    \n",
    "    # Формируем списки тензоров\n",
    "    for _label, _text in batch:\n",
    "        # Режим тренировки\n",
    "        if _label is not None:\n",
    "            if label_list is None:\n",
    "                label_list = []\n",
    "            label_list.append(_label)\n",
    "        \n",
    "        processed_text = torch.tensor(vocab(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        \n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    # Преобразуем списки тензоров в тензор и выравниваем последовательности\n",
    "    if label_list:\n",
    "        label_list = torch.FloatTensor(np.array(label_list)).to(device)\n",
    "        \n",
    "    offsets = torch.tensor(np.array(offsets), dtype=torch.int64).to(device)\n",
    "    text_list = pad_sequence(text_list, padding_value=PAD_INDEX).permute(1, 0).to(device)\n",
    "    \n",
    "    # Сортируем\n",
    "    offsets, ordering = torch.sort(offsets, dim=0, descending=True)\n",
    "    text_list = text_list[ordering]\n",
    "    if label_list is not None:\n",
    "        label_list = label_list[ordering].to(device)\n",
    "   \n",
    "        \n",
    "    return text_list.to(device), label_list\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.1, random_state=random_state, shuffle=False)\n",
    "# , num_workers=11, persistent_workers=True\n",
    "train_loader = DataLoader(WordDataset(X_train, y_train), batch_size=64, shuffle=True, drop_last=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(WordDataset(X_test, y_test), batch_size=64, shuffle=False, drop_last=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение модели\n",
    "\n",
    "Для предсказывания меток попробуем использовать рекурентные нейронные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "RNN_HIDDEN_DIM = 100\n",
    "RNN_NUM_LAYERS = 1\n",
    "MAX_EPOCHS=5\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, aggregation_type: Optional[str]='last'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBEDDING_DIM, padding_idx = PAD_INDEX)\n",
    "        self.rnn = nn.RNN(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        # self.rnn = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        # self.rnn = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        self.linear = nn.Linear(RNN_HIDDEN_DIM, len(multi_label.classes_))\n",
    "        \n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding(X_batch)\n",
    "        output, _ = self.rnn(embeddings)\n",
    "        \n",
    "        if self.aggregation_type == 'max':\n",
    "            output = output.max(dim=1)\n",
    "        elif self.aggregation_type == 'mean':\n",
    "            output = output.mean(dim=1) \n",
    "        elif self.aggregation_type == 'last':\n",
    "            output = output[:,-1]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation_type\")\n",
    "        \n",
    "        return self.linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "class TextClassificationLightningModule(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        \n",
    "        self.model = model\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def predict_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        probs = self.sigmoid(logits)        \n",
    "        preds = torch.round(probs)\n",
    "        \n",
    "        return probs, preds, y\n",
    "\n",
    "    def training_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, y)        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        prob = self.sigmoid(logits)        \n",
    "        preds = torch.round(prob)\n",
    "        \n",
    "        test_loss = F.mse_loss(preds, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "    def validation_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        prob = self.sigmoid(logits)        \n",
    "        preds = torch.round(prob)\n",
    "        \n",
    "        val_loss = F.mse_loss(preds, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "\n",
      "  | Name    | Type                    | Params\n",
      "----------------------------------------------------\n",
      "0 | model   | TextClassificationModel | 609 M \n",
      "1 | sigmoid | Sigmoid                 | 0     \n",
      "----------------------------------------------------\n",
      "609 M     Trainable params\n",
      "0         Non-trainable params\n",
      "609 M     Total params\n",
      "2,437.157 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc2dd12f3a546598364fe6ff33cd708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea5fe3c419a44719c9743b119ef2e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af070edd1e44b4f8842ecdc87e0f261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bafd467c8b48e8a7a776b643e49de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844c4a724974493f854be97a2ed50bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f12da8ccb96489baa0be678f72d36a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7633fd9e4d74c09885d6b2314a74fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = TextClassificationLightningModule(TextClassificationModel())\n",
    "trainer = L.Trainer(max_epochs=MAX_EPOCHS, default_root_dir=\"data/models/\")\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88494a563faf4554b40b03d308409496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.10188309103250504\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10188309103250504}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка модели\n",
    "\n",
    "Оценим метрики scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95770929ee2848b3b09e60b1fe108ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_batches = trainer.predict(model, valid_loader)\n",
    "probs=[]\n",
    "preds=[]\n",
    "y_valid = []\n",
    "for _probs, _preds, _y in preds_batches:\n",
    "    probs.append(_probs)\n",
    "    preds.append(_preds)\n",
    "    y_valid.append(_y)\n",
    "\n",
    "probs = torch.vstack(probs)[:,1].reshape(-1, 1).cpu().detach().numpy().tolist()\n",
    "preds = torch.vstack(preds).cpu().detach().numpy().tolist()\n",
    "y_valid = torch.vstack(y_valid).cpu().detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n",
      "\n",
      "precision: [0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.036, 0.0, 0.0, 0.004048582995951417, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008097165991902834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.076, 0.0, 0.092, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0040650406504065045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008097165991902834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012096774193548387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004, 0.004, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012, 0.0, 0.0, 0.0, 0.0, 0.008, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008097165991902834, 0.0, 0.0, 0.0, 0.0, 0.004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "recall: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "f1: [0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023715415019762848, 0.06949806949806948, 0.0, 0.0, 0.00806451612903226, 0.0, 0.0, 0.015873015873015872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.14126394052044608, 0.0, 0.16849816849816848, 0.0, 0.00796812749003984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00796812749003984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.023715415019762848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023715415019762848, 0.0, 0.008097165991902834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12734082397003746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2578397212543554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2332155477031802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08429118773946359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.046875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12734082397003746, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023715415019762848, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3870967741935484, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0988593155893536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054474708171206226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023904382470119518, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00796812749003984, 0.00796812749003984, 0.00796812749003984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.054474708171206226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.00796812749003984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031746031746031744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.023715415019762848, 0.0, 0.0, 0.0, 0.0, 0.015873015873015872, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031496062992125984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0392156862745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.00796812749003984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.054474708171206226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "auc: [0.51209677]\n",
      "\n",
      "hamming: 0.1018310291858679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid, preds)\n",
    "precision = precision_score(y_valid, preds, average=None, zero_division=0)\n",
    "recall = recall_score(y_valid, preds, average=None, zero_division=0)\n",
    "f1 = f1_score(y_valid, preds, average=None, zero_division=0)\n",
    "auc = roc_auc_score(y_valid, probs, average=None)\n",
    "hamming = hamming_loss(y_valid, preds)\n",
    "\n",
    "\n",
    "print(f'accuracy: {accuracy}\\n')\n",
    "print(f'precision: {list(precision)}\\n')\n",
    "print(f'recall: {list(recall)}\\n')\n",
    "print(f'f1: {list(f1)}\\n')\n",
    "print(f'auc: {auc}\\n')\n",
    "print(f'hamming: {hamming}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: \n",
      "<p>Какая команда наиболее проста и удобна?</p>\n",
      "\n",
      "Предсказанные теги: \n",
      "[('.net', '1с', 'actionscript', 'actionscript-3', 'ajax', 'android', 'android-adb', 'ant', 'asp.net', 'awt', 'c', 'c#', 'c++', 'c++-faq', 'c++builder', 'canvas', 'case', 'centos', 'chrome-extension', 'code-coverage', 'concurrency', 'cookie', 'corel-draw', 'cpu', 'css', 'curl', 'd', 'dbgrid', 'desktop', 'django', 'dll', 'ejb', 'email', 'exif', 'extjs', 'flash', 'fortran', 'ftp', 'g++', 'glassfish', 'grep', 'gtk', 'gwt', 'hql', 'html', 'ide', 'ios', 'ipad', 'java', 'java-ee', 'javascript', 'javaws', 'jquery', 'jquery-ui', 'jstl', 'linq', 'linq2sql', 'linux', 'makefile', 'mfc', 'mingw', 'mvc', 'mysql', 'objective-c', 'openid', 'opensource', 'oracle', 'photo', 'php', 'prolog', 'putty', 'pygtk', 'python', 'qt', 'rmi', 'rspec', 'ruby', 'ruby-on-rails', 'samba', 'screen', 'silverlight', 'soap', 'sql', 'sqlite', 'su', 'svn', 'ubuntu', 'udp', 'upload', 'usb', 'vbscript', 'vista', 'visual-basic', 'visual-c++', 'visual-studio', 'vmware', 'wcf', 'windows', 'winforms', 'winsock', 'wix', 'xcode', 'xhtml', 'xml', 'xmpp', 'администрирование', 'алгоритм', 'аннотации', 'ассемблер', 'бинарное-дерево', 'веб-программирование', 'веб-сервер', 'вёрстка', 'гистограммы', 'графика', 'декомпиляция', 'документация', 'домен', 'исключения', 'клиент-сервер', 'контроль-версий', 'маршрутизатор', 'массивы', 'методы', 'наследование', 'ооп', 'оптимизация', 'отладка', 'перекодировка', 'потоки-данных', 'почта', 'профилирование', 'процесс', 'работа', 'распараллеливание', 'регулярные-выражения', 'реестр', 'резервное-копирование', 'роутер', 'сервлеты', 'сеть', 'синтаксический-анализ', 'сокет', 'сокеты', 'сортировка', 'ссылки', 'таймер', 'теги', 'терминология', 'уязвимости', 'файлы')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "valid_df = df.iloc[:10, :]\n",
    "valid_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "row_num = random.randint(0, valid_df.shape[0])\n",
    "text = valid_df['Body'][row_num]\n",
    "tokens = preprocessor(text)\n",
    "\n",
    "\n",
    "print(f'Текст: \\n{text}\\n')\n",
    "\n",
    "processed_text = torch.tensor(vocab(tokens), dtype=torch.int64)\n",
    "processed_text = pad_sequence([processed_text], padding_value=PAD_INDEX).permute(1, 0).to(device)\n",
    "model.model.to(device)\n",
    "model.model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model.model(processed_text)\n",
    "    \n",
    "    prob = torch.nn.Sigmoid()(logits)        \n",
    "    preds = torch.round(prob)\n",
    "    \n",
    "# prob, ordering = torch.sort(prob, descending=True)\n",
    "# preds = preds[ordering]\n",
    "\n",
    "\n",
    "labels = multi_label.inverse_transform(preds.cpu().reshape(1, -1))\n",
    "print(f'Предсказанные теги: \\n{labels}\\n')\n",
    "\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "Обучение сети на CPU также занимает очень длительное время. Однако если задействовать GPU, то эффективность обучения очень сильно повысится по сравнению с CatBoostClassifier, который требует очень большое количество GPU единовременно. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
