{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gorinenko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gorinenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, hamming_loss\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import lightning as L\n",
    "    \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "В второй части w2v_base_line.ipynb мы составили базовый pipeline обучение модели CatBoostClassifier на базе признаков, извлеченных с использованием Word2Vec. В этом документе попробуем использовать рекурентные сети для предсказания меток-тегов и сравним скорость обучения модели и ее предсказательную способность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples count 5000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/stackoverflow_posts.csv'\n",
    "# file_path = '/content/drive/MyDrive/stackoverflow_posts.csv'\n",
    "\n",
    "nrows = 20_000\n",
    "# 300_000\n",
    "raw_df = pd.read_csv(file_path)\n",
    "df = raw_df[~raw_df['Tags'].isna()]\n",
    "\n",
    "df = df.iloc[:nrows, :]\n",
    "df.reset_index(inplace=True)\n",
    "# Всего - 912090\n",
    "\n",
    "print(f'samples count {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tags(value):\n",
    "    tags = value.replace('<', '').split('>')\n",
    "    return [tag for tag in tags if tag]\n",
    "\n",
    "    \n",
    "df[\"Tags\"] = df[\"Tags\"].apply(lambda x: parse_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "\n",
    "class TextPreProcessor:\n",
    "    def __init__(self, tokenizer, stemmer=None, morph=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.morph = morph\n",
    "\n",
    "\n",
    "    def tokenize(self, text: str):      \n",
    "        text = text.lower()\n",
    "      \n",
    "        doc = BeautifulSoup(text, 'lxml')\n",
    "        text = doc.text\n",
    "        \n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        words = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "        \n",
    "        if self.morph:\n",
    "            words = [self.morph.parse(word)[0].normal_form for word in words]\n",
    "\n",
    "        if self.stemmer:\n",
    "            words = [self.stemmer.stem(word) for word in words]\n",
    "\n",
    "        return words\n",
    "    \n",
    "class NltkTokenizer:    \n",
    "    def tokenize(self, text: str):      \n",
    "        return list(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим словарь, который сопоставляет словам некие индексы. Мы используем специальный токен **unk**, который будет возвращен, если слово отсутствует в словаре. Внутри себя функция подсчитывает частоту появления каждого токена, потом слова сортируются по убыванию частоты и из уже отсортированного словаря строиться vocab. Таким образом самые часто встречаемые слова будут в начале(специальный токен **unk** имеет индекс 0). В словаре также имеется токен **pad**, который дополняет предложение до определенной длины, если оно меньше, например, если мы условились, что длина последовательности равна 10, то предложение 'here is the an example' будет закодировано так 'here is the an example pad pad pad pad pad'. Только на месте чисел должны стоять их индексы в словаре.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g5/8xrz2mg176j1yxttghxsl4gc0000gn/T/ipykernel_29966/2654832454.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  doc = BeautifulSoup(text, 'lxml')\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    if not isinstance(text, str):\n",
    "          return text\n",
    "      \n",
    "    tokenizer = TextPreProcessor(tokenizer=NltkTokenizer())    \n",
    "    words = tokenizer.tokenize(text)\n",
    "    return words\n",
    "    \n",
    "def yield_tokens(data_iter):\n",
    "    for tokens in data_iter:\n",
    "        yield preprocessor(tokens)\n",
    "        \n",
    "df['Body'] = df['Body'].apply(lambda x: preprocessor(x))\n",
    "        \n",
    "vocab = build_vocab_from_iterator(yield_tokens(df['Body']), specials=['<unk>', '<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря 27451\n",
      "Индексы слов [118, 24820, 0, 0]\n",
      "Слово с индексом 100 - \"такое\"\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер словаря {len(vocab)}')\n",
    "print(f'Индексы слов {vocab([\"javascript\", \"принтер\", \"abra-cadabra\", \"<unk>\"])}')\n",
    "print(f'Слово с индексом 100 - \"{vocab.lookup_token(100)}\"')\n",
    "\n",
    "PAD_INDEX=vocab['<pad>']\n",
    "UNK_INDEX=vocab['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_label = MultiLabelBinarizer()\n",
    "Y = multi_label.fit_transform(list(df[\"Tags\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, создадим WordDataset и DataLoader с использованием функции collate_batch, которая будет формировать пакеты наших данных. Обратите внимание, что архитектура RNN требует, чтобы все предложения в пакете данных для обучения на каком-то шаге имели одинаковую длину. Поэтому в процессе формирования пакетов преобразуем токены текста в индексы подготовленного словаря, а затем дополним последовательности индексом специального символа **pad**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordDataset:\n",
    "    def __init__(self, data,  encode_labels=None):\n",
    "        self.data = data['Body']\n",
    "        self.encode_labels = encode_labels #None if encode_labels is None else np.array(encode_labels)\n",
    "        assert len(self.data) == len(self.encode_labels)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.encode_labels is None:\n",
    "            return None, self.data.iloc[idx]\n",
    "        \n",
    "        return self.encode_labels[idx], self.data.iloc[idx]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "random_state=42\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "text_pipeline = lambda x: vocab(x)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = None, [], []\n",
    "    \n",
    "    # Формируем списки тензоров\n",
    "    for _label, _text in batch:\n",
    "        # Режим тренировки\n",
    "        if _label is not None:\n",
    "            if label_list is None:\n",
    "                label_list = []\n",
    "            label_list.append(_label)\n",
    "        \n",
    "        processed_text = torch.tensor(vocab(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        \n",
    "        offsets.append(processed_text.size(0))\n",
    "    \n",
    "    # Преобразуем списки тензоров в тензор и выравниваем последовательности\n",
    "    if label_list:\n",
    "        label_list = torch.FloatTensor(np.array(label_list)).to(device)\n",
    "        \n",
    "    offsets = torch.tensor(np.array(offsets), dtype=torch.int64).to(device)\n",
    "    text_list = pad_sequence(text_list, padding_value=PAD_INDEX).permute(1, 0).to(device)\n",
    "    \n",
    "    # Сортируем\n",
    "    offsets, ordering = torch.sort(offsets, dim=0, descending=True)\n",
    "    text_list = text_list[ordering]\n",
    "    if label_list is not None:\n",
    "        label_list = label_list[ordering].to(device)\n",
    "   \n",
    "        \n",
    "    return text_list.to(device), label_list\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, Y, test_size=0.1, random_state=random_state, shuffle=False)\n",
    "# , num_workers=11, persistent_workers=True\n",
    "train_loader = DataLoader(WordDataset(X_train, y_train), batch_size=256, shuffle=True, drop_last=True, collate_fn=collate_batch)\n",
    "valid_loader = DataLoader(WordDataset(X_test, y_test), batch_size=256, shuffle=False, drop_last=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение модели\n",
    "\n",
    "Для предсказывания меток попробуем использовать рекурентные нейронные сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "RNN_HIDDEN_DIM = 100\n",
    "RNN_NUM_LAYERS = 1\n",
    "MAX_EPOCHS=25\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    def __init__(self, aggregation_type: Optional[str]='last'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.aggregation_type = aggregation_type\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=EMBEDDING_DIM, padding_idx = PAD_INDEX)\n",
    "        self.rnn = nn.RNN(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        # self.rnn = nn.GRU(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        # self.rnn = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=RNN_HIDDEN_DIM, num_layers=RNN_NUM_LAYERS, batch_first=True)\n",
    "        self.linear = nn.Linear(RNN_HIDDEN_DIM, len(multi_label.classes_))\n",
    "        \n",
    "    def forward(self, X_batch):\n",
    "        embeddings = self.embedding(X_batch)\n",
    "        output, _ = self.rnn(embeddings)\n",
    "        \n",
    "        if self.aggregation_type == 'max':\n",
    "            output = output.max(dim=1)\n",
    "        elif self.aggregation_type == 'mean':\n",
    "            output = output.mean(dim=1) \n",
    "        elif self.aggregation_type == 'last':\n",
    "            output = output[:,-1]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation_type\")\n",
    "        \n",
    "        return self.linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "\n",
    "class TextClassificationLightningModule(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        \n",
    "        self.model = model\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def predict_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        probs = self.sigmoid(logits)        \n",
    "        preds = torch.round(probs)\n",
    "        \n",
    "        return probs, preds, y\n",
    "\n",
    "    def training_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, y)        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        prob = self.sigmoid(logits)        \n",
    "        preds = torch.round(prob)\n",
    "        \n",
    "        test_loss = F.mse_loss(preds, y)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "    def validation_step(self, batch, *args):\n",
    "        X, y = batch\n",
    "        logits = self.model(X)\n",
    "        \n",
    "        prob = self.sigmoid(logits)        \n",
    "        preds = torch.round(prob)\n",
    "        \n",
    "        val_loss = F.mse_loss(preds, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                    | Params\n",
      "----------------------------------------------------\n",
      "0 | model   | TextClassificationModel | 5.6 M \n",
      "1 | sigmoid | Sigmoid                 | 0     \n",
      "----------------------------------------------------\n",
      "5.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 M     Total params\n",
      "22.345    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf04eeab8ac4a7f8a4408bf21c8e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a742815c76ef42b99a6110c2bb012a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e014c4221f49f6b3de30be0f5dd718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = TextClassificationLightningModule(TextClassificationModel())\n",
    "trainer = L.Trainer(max_epochs=MAX_EPOCHS, default_root_dir=\"data/models/\")\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45e1fbc4bde45b4a51f7a9d130031fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.14868952333927155\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.14868952333927155}]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка модели\n",
    "\n",
    "Оценим метрики scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorinenko/src/multi_tagging_classification/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b926f679ab4b0d9fedc0fb96ac2950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_batches = trainer.predict(model, valid_loader)\n",
    "probs=[]\n",
    "preds=[]\n",
    "y_valid = []\n",
    "for _probs, _preds, _y in preds_batches:\n",
    "    probs.append(_probs)\n",
    "    preds.append(_preds)\n",
    "    y_valid.append(_y)\n",
    "\n",
    "probs = torch.vstack(probs)[:,1].reshape(-1, 1).cpu().detach().numpy().tolist()\n",
    "preds = torch.vstack(preds).cpu().detach().numpy().tolist()\n",
    "y_valid = torch.vstack(y_valid).cpu().detach().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n",
      "\n",
      "precision: [0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.03614457831325301, 0.0, 0.0, 0.004032258064516129, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008097165991902834, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020080321285140562, 0.07630522088353414, 0.0, 0.09236947791164658, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020080321285140562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.004032258064516129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024096385542168676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06827309236947791, 0.0, 0.004032258064516129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14859437751004015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13253012048192772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04417670682730924, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024096385542168676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06827309236947791, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23694779116465864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05220883534136546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008064516129032258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024096385542168676, 0.0, 0.0, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.004032258064516129, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020080321285140562, 0.028112449799196786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004032258064516129, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012048192771084338, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004032258064516129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016129032258064516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.020080321285140562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.004016064257028112, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.028112449799196786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "recall: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9833333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "f1: [0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02380952380952381, 0.06976744186046512, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01606425702811245, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03937007874015748, 0.1417910447761194, 0.0, 0.1691176470588235, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03937007874015748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.02380952380952381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02380952380952381, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047058823529411764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12781954887218047, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2587412587412587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23404255319148937, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0846153846153846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047058823529411764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12781954887218047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02380952380952381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3818770226537217, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09923664122137404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04687500000000001, 0.0, 0.0, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02380952380952381, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.008032128514056224, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03937007874015748, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02380952380952381, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03162055335968379, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008032128514056224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031746031746031744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03937007874015748, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015936254980079678, 0.0, 0.0, 0.0, 0.0, 0.007999999999999998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0546875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "auc: [0.50604839]\n",
      "\n",
      "hamming: 0.1459846390168971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_valid, preds)\n",
    "precision = precision_score(y_valid, preds, average=None, zero_division=0)\n",
    "recall = recall_score(y_valid, preds, average=None, zero_division=0)\n",
    "f1 = f1_score(y_valid, preds, average=None, zero_division=0)\n",
    "auc = roc_auc_score(y_valid, probs, average=None)\n",
    "hamming = hamming_loss(y_valid, preds)\n",
    "\n",
    "\n",
    "print(f'accuracy: {accuracy}\\n')\n",
    "print(f'precision: {list(precision)}\\n')\n",
    "print(f'recall: {list(recall)}\\n')\n",
    "print(f'f1: {list(f1)}\\n')\n",
    "print(f'auc: {auc}\\n')\n",
    "print(f'hamming: {hamming}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df[df['Tags'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: \n",
      "<p>Есть поле ввода, мы вводим число и оно выводит так\n",
      "Ввод 1172458\n",
      "Вывод (1172) (458) всмысле выводит первые четыре цифры и последные три это нужно сделать без splice или стринг метода, есть варианты?</p>\n",
      "<p><div class=\"snippet\" data-lang=\"js\" data-hide=\"false\" data-console=\"true\" data-babel=\"false\">\n",
      "<div class=\"snippet-code\">\n",
      "<pre class=\"snippet-code-html lang-html prettyprint-override\"><code>&lt;input type = 'number'&gt;\n",
      "&lt;button&gt;OK &lt;/button&gt;\n",
      "&lt;p class = \"first\"&gt;&lt;/p&gt;\n",
      "&lt;p class = \"second\"&gt;&lt;/p&gt;</code></pre>\n",
      "</div>\n",
      "</div>\n",
      "</p>\n",
      "\n",
      "\n",
      "Предсказанные теги: \n",
      "[('.net', 'android', 'android-ndk', 'apache', 'aptana', 'asp.net', 'bash', 'c', 'c#', 'c++', 'c++builder', 'clearcase', 'cocoa', 'cp1251', 'css', 'd-link', 'debian', 'delphi', 'desktop', 'diff', 'django', 'dll', 'eclipse', 'elf', 'email', 'extjs', 'firewall', 'flash', 'gcc', 'glassfish', 'golang', 'google-chrome', 'gwt', 'html', 'http', 'ide', 'im', 'interbase', 'ios', 'ipad', 'iphone', 'java', 'javafx', 'javascript', 'jquery', 'jsp', 'linq', 'linux', 'llvm', 'mac', 'mercurial', 'mfc', 'mysql', 'objective-c', 'oracle', 'pascal', 'perl', 'php', 'python', 'ruby', 'silverlight', 'sql', 'ssh', 'swing', 'ubuntu', 'unix', 'vista', 'visual-basic', 'visual-c++', 'visual-studio', 'winapi', 'windows', 'winforms', 'winsock', 'wordpress', 'wpf', 'xaml', 'xml', 'алгоритм', 'ассемблер', 'база-данных', 'веб-программирование', 'вёрстка', 'графика', 'графы', 'дерево', 'документация', 'железо', 'книги', 'любой-язык', 'многопоточность', 'нейронные-сети', 'отладка', 'потоки-данных', 'профилирование', 'работа', 'регулярные-выражения', 'сервер', 'сеть', 'сокет', 'сортировка', 'тестирование', 'фильтры', 'шаблоны-проектирования', 'шаблоны-с++')]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "valid_df = raw_df[~raw_df['Tags'].isna()]\n",
    "valid_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "row_num = random.randint(0, valid_df['Body'].shape[0])\n",
    "text = valid_df['Body'][row_num]\n",
    "tokens = preprocessor(text)\n",
    "\n",
    "\n",
    "print(f'Текст: \\n{text}\\n')\n",
    "\n",
    "processed_text = torch.tensor(vocab(tokens), dtype=torch.int64)\n",
    "processed_text = pad_sequence([processed_text], padding_value=PAD_INDEX).permute(1, 0).to(device)\n",
    "model.model.to(device)\n",
    "model.model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model.model(processed_text)\n",
    "    \n",
    "    prob = torch.nn.Sigmoid()(logits)        \n",
    "    preds = torch.round(prob)\n",
    "\n",
    "\n",
    "labels = multi_label.inverse_transform(preds.cpu().reshape(1, -1))\n",
    "print(f'Предсказанные теги: \\n{labels}\\n')\n",
    "\n",
    "len(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "Обучение сети на CPU также занимает очень длительное время. Однако если задействовать GPU, то эффективность обучения очень сильно повысится по сравнению с CatBoostClassifier, который требует очень большое количество GPU единовременно. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
